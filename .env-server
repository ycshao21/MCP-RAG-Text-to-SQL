### Server Configuration
HOST=127.0.0.1
PORT=8021
WORKERS=4

OPENAI_API_KEY=sk-iehJolTMhTG3RrdUD2De7a723fDd4c35BaC5C27e7c84982e
OPENAI_BASE_URL=https://apione.zen-x.com.cn/api/v1

### Settings for document indexing
ENABLE_LLM_CACHE_FOR_EXTRACT=true
ENABLE_LLM_CACHE=true
SUMMARY_LANGUAGE=Chinese
MAX_PARALLEL_INSERT=4
PYTHONIOENCODING=utf-8
EMBEDDING_FUNC_MAX_ASYNC=16

### LLM Configuration (Use valid host. For local services installed with docker, you can use host.docker.internal)
TIMEOUT=200
TEMPERATURE=0.0
MAX_ASYNC=16
MAX_TOKENS=32768
MAX_GRAPH_NODES=10000

LLM_BINDING=openai
LLM_MODEL=gpt-4o-mini
LLM_BINDING_HOST=https://apione.zen-x.com.cn/api/v1
LLM_BINDING_API_KEY=sk-iehJolTMhTG3RrdUD2De7a723fDd4c35BaC5C27e7c84982e

### Embedding Configuration (Use valid host. For local services installed with docker, you can use host.docker.internal)
EMBEDDING_BINDING=openai
EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_DIM=1024
EMBEDDING_BINDING_HOST=https://api.siliconflow.cn/v1
EMBEDDING_BINDING_API_KEY=sk-xqdxcyjftnhbffhjpylncjhniyyfjteeeljmatnqbnperztm